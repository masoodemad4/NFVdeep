env is <Env instance>
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
properties are: {'num_nodes': 12, 'num_node_resources': 3}
Logging to /workspaces/NFVdeep/resuls/logs/PPO_28
-----------------------------
| time/              |      |
|    fps             | 722  |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
properties are: {'num_nodes': 12, 'num_node_resources': 3}
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.44e+03     |
|    ep_rew_mean          | 4.36e+05     |
| time/                   |              |
|    fps                  | 637          |
|    iterations           | 2            |
|    time_elapsed         | 6            |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0010935424 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 2.26e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.24e+07     |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00246     |
|    value_loss           | 2.09e+07     |
------------------------------------------
properties are: {'num_nodes': 12, 'num_node_resources': 3}
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 4.29e+05    |
| time/                   |             |
|    fps                  | 606         |
|    iterations           | 3           |
|    time_elapsed         | 10          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.001561045 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 6.56e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.91e+06    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00339    |
|    value_loss           | 2.02e+07    |
-----------------------------------------
properties are: {'num_nodes': 12, 'num_node_resources': 3}
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.52e+03     |
|    ep_rew_mean          | 4.32e+05     |
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 4            |
|    time_elapsed         | 13           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0011967415 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 2.38e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 7.07e+06     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00254     |
|    value_loss           | 1.9e+07      |
------------------------------------------
properties are: {'num_nodes': 12, 'num_node_resources': 3}
properties are: {'num_nodes': 12, 'num_node_resources': 3}
properties are: {'num_nodes': 12, 'num_node_resources': 3}
properties are: {'num_nodes': 12, 'num_node_resources': 3}
properties are: {'num_nodes': 12, 'num_node_resources': 3}
properties are: {'num_nodes': 12, 'num_node_resources': 3}
Eval num_timesteps=10000, episode_reward=484836.73 +/- 13528.61
Episode length: 2576.00 +/- 13.46
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 2.58e+03      |
|    mean_reward          | 4.85e+05      |
| time/                   |               |
|    total_timesteps      | 10000         |
| train/                  |               |
|    approx_kl            | 0.00079575344 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.55         |
|    explained_variance   | 1.79e-07      |
|    learning_rate        | 0.0003        |
|    loss                 | 1.26e+07      |
|    n_updates            | 40            |
|    policy_gradient_loss | -0.00189      |
|    value_loss           | 1.97e+07      |
-------------------------------------------
New best mean reward!
properties are: {'num_nodes': 12, 'num_node_resources': 3}
--------------------------------------------
| eval/                         |          |
|    acceptance_ratio           | 0.484    |
|    mean_bandwidth_cost        | 3.14     |
|    mean_bandwidth_utilization | 1.77e+03 |
|    mean_cpu_cost              | 465      |
|    mean_cpu_utilization       | 660      |
|    mean_memory_cost           | 68.6     |
|    mean_memory_utilization    | 3.61e+03 |
|    mean_operating_servers     | 8.68     |
|    rejection_ratio            | 0.516    |
| rollout/                      |          |
|    ep_len_mean                | 2.54e+03 |
|    ep_rew_mean                | 4.5e+05  |
| time/                         |          |
|    fps                        | 295      |
|    iterations                 | 5        |
|    time_elapsed               | 34       |
|    total_timesteps            | 10240    |
--------------------------------------------
